{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3edb2b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "# 导入评估指标模块\n",
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix, f1_score, precision_score, recall_score, roc_curve\n",
    "# 导入表格库\n",
    "import prettytable\n",
    "# 导入dot插件库\n",
    "import pydotplus\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e58dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(536, 17)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_data = pd.read_csv('labelled_whitelist_shop2.csv')\n",
    "labelled_data.shape\n",
    "# labelled_data['kmeans_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7ac369f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 536 entries, 0 to 535\n",
      "Data columns (total 17 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   manage_shop_indicator          536 non-null    float64\n",
      " 1   officialstore_indicator        536 non-null    float64\n",
      " 2   preferred_shop_indicator       536 non-null    float64\n",
      " 3   crossborder_indicator          536 non-null    float64\n",
      " 4   shop_category                  536 non-null    float64\n",
      " 5   new_seller_flag                536 non-null    float64\n",
      " 6   seller_centre_login_L30D       536 non-null    float64\n",
      " 7   shop_sku_number                536 non-null    float64\n",
      " 8   shop_follower_number           536 non-null    float64\n",
      " 9   shop_L180D_order               536 non-null    float64\n",
      " 10  weighted_shop_rating           536 non-null    float64\n",
      " 11  kmeans.labels                  536 non-null    int64  \n",
      " 12  agglomerative.average.labels   536 non-null    int64  \n",
      " 13  agglomerative.complete.labels  536 non-null    int64  \n",
      " 14  agglomerative.single.labels    536 non-null    int64  \n",
      " 15  agglomerative.ward.labels      536 non-null    int64  \n",
      " 16  meanshift.labels               536 non-null    int64  \n",
      "dtypes: float64(11), int64(6)\n",
      "memory usage: 71.3 KB\n",
      "0    493\n",
      "4     27\n",
      "2     10\n",
      "1      4\n",
      "3      2\n",
      "Name: kmeans.labels, dtype: int64\n",
      "1    244\n",
      "0    185\n",
      "2     48\n",
      "4     34\n",
      "3     25\n",
      "Name: agglomerative.average.labels, dtype: int64\n",
      "2    203\n",
      "0    199\n",
      "1     72\n",
      "4     41\n",
      "3     21\n",
      "Name: agglomerative.complete.labels, dtype: int64\n",
      "0     478\n",
      "1      21\n",
      "2       5\n",
      "3       4\n",
      "6       4\n",
      "4       3\n",
      "5       3\n",
      "7       2\n",
      "16      1\n",
      "22      1\n",
      "21      1\n",
      "20      1\n",
      "19      1\n",
      "18      1\n",
      "17      1\n",
      "12      1\n",
      "15      1\n",
      "14      1\n",
      "13      1\n",
      "11      1\n",
      "10      1\n",
      "9       1\n",
      "8       1\n",
      "23      1\n",
      "Name: meanshift.labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "labelled_data.info()\n",
    "# labelled_data.tail(20)\n",
    "print(labelled_data['kmeans.labels'].value_counts())\n",
    "print(labelled_data['agglomerative.average.labels'].value_counts())\n",
    "print(labelled_data['agglomerative.complete.labels'].value_counts())\n",
    "print(labelled_data['meanshift.labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2c0d1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26018 entries, 119700 to 1486953315\n",
      "Data columns (total 11 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   manage_shop_indicator     26018 non-null  float64\n",
      " 1   officialstore_indicator   26018 non-null  float64\n",
      " 2   preferred_shop_indicator  26018 non-null  float64\n",
      " 3   crossborder_indicator     26018 non-null  float64\n",
      " 4   shop_category             26018 non-null  float64\n",
      " 5   new_seller_flag           26018 non-null  float64\n",
      " 6   seller_centre_login_L30D  26018 non-null  float64\n",
      " 7   shop_sku_number           26018 non-null  float64\n",
      " 8   shop_follower_number      26018 non-null  float64\n",
      " 9   shop_L180D_order          26018 non-null  float64\n",
      " 10  weighted_shop_rating      26018 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "#process non-whitelist data\n",
    "non_whitelist = pd.read_csv('non_whitelist_filled.csv')\n",
    "nw_data = non_whitelist.groupby(\"shop_index\").mean()\n",
    "nw_data = nw_data.drop(columns=['decorated_indicator','Unnamed: 0','performance_date','masked_item_impression','masked_order','masked_shop_page_view','masked_shop_click_from_search','masked_campaign_tab_click','masked_other_tab_click'])\n",
    "nw_data.head(20)\n",
    "nw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ebb026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agglomerative.average.labels \n",
    "#define x,y\n",
    "x = labelled_data.iloc[:,:11]\n",
    "y = labelled_data.iloc[:,-5]\n",
    "#get train/test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1fefbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "#model training\n",
    "dt_model = DecisionTreeClassifier(random_state=2018)\n",
    "dt_model.fit(x_train, y_train)\n",
    "#test the model with test dataset\n",
    "pre_y = dt_model.predict(x_test)\n",
    "accuracy_s = accuracy_score(y_test, pre_y)\n",
    "accuracy_s\n",
    "y_score = dt_model.predict_proba(x_test)\n",
    "y_score\n",
    "\n",
    "#prediction on non-whitelist data\n",
    "prediction1 = dt_model.predict(nw_data)\n",
    "prediction1\n",
    "prob1 = dt_model.predict_proba(nw_data)\n",
    "prob1[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c9b90f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "[[0.89 0.09 0.01 0.   0.01]\n",
      " [0.98 0.02 0.   0.   0.  ]\n",
      " [0.95 0.   0.05 0.   0.  ]\n",
      " [0.34 0.51 0.05 0.08 0.02]\n",
      " [0.97 0.02 0.01 0.   0.  ]\n",
      " [0.96 0.03 0.01 0.   0.  ]\n",
      " [0.93 0.04 0.03 0.   0.  ]\n",
      " [0.77 0.15 0.07 0.   0.01]\n",
      " [0.96 0.02 0.02 0.   0.  ]\n",
      " [0.1  0.86 0.01 0.03 0.  ]\n",
      " [0.75 0.03 0.18 0.   0.04]\n",
      " [0.94 0.03 0.03 0.   0.  ]\n",
      " [0.95 0.   0.05 0.   0.  ]\n",
      " [0.97 0.02 0.01 0.   0.  ]\n",
      " [0.92 0.03 0.05 0.   0.  ]\n",
      " [0.96 0.   0.04 0.   0.  ]\n",
      " [0.86 0.06 0.08 0.   0.  ]\n",
      " [0.75 0.19 0.04 0.01 0.01]\n",
      " [0.96 0.   0.03 0.   0.01]\n",
      " [0.96 0.01 0.02 0.   0.01]]\n",
      "unmatched num:  7682\n"
     ]
    }
   ],
   "source": [
    "#random forest(currently good)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create the model with 100 trees\n",
    "rf_model = RandomForestClassifier(n_estimators=100, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "# Fit on training data\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Actual class predictions\n",
    "rf_predictions = rf_model.predict(x_test)\n",
    "\n",
    "# Probabilities for each class\n",
    "rf_probs =rf_model.predict_proba(x_test)[:, 1]\n",
    "# rf_probs\n",
    "rf_predictions\n",
    "\n",
    "#prediction on non_whitelist data\n",
    "predictions = rf_model.predict(nw_data)\n",
    "print(predictions[20:40])\n",
    "proba = rf_model.predict_proba(nw_data)\n",
    "print(proba[20:40])\n",
    "proba = list(proba)\n",
    "count = 0\n",
    "for i in proba:\n",
    "    if max(i)<0.7:\n",
    "        count += 1\n",
    "print(\"unmatched num: \",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fc8a018e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#data\n",
    "x = labelled_data.iloc[:,:11]\n",
    "y = labelled_data.iloc[:,-5]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,random_state=0,train_size=0.7)\n",
    "ss_x = StandardScaler()\n",
    "ss_y = StandardScaler()\n",
    "x_train = ss_x.fit_transform(x_train)\n",
    "x_test = ss_x.transform(x_test)\n",
    "\n",
    "#model training\n",
    "model_GBDT = GradientBoostingClassifier(random_state=10)\n",
    "model_GBDT.fit(x_train,y_train)\n",
    "y_pred = model_GBDT.predict(x_train)\n",
    "y_predprob = model_GBDT.predict_proba(x_train)[:,1]\n",
    "\n",
    "#predict on non whitelist data\n",
    "model_GBDT.predict(nw_data.head(20))\n",
    "prob_GBDT = model_GBDT.predict_proba(nw_data)\n",
    "prob_GBDT\n",
    "count_GBDT = 0\n",
    "for i in range(len(prob_GBDT)):\n",
    "    if np.max(prob_GBDT[i])<0.8:\n",
    "        count_GBDT += 1\n",
    "print(count_GBDT)\n",
    "#     print(np.max(prob_GBDT[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "27388b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8298457409063978"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83c0943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost (----------------to be edited, 还是报错)\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c70121cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = labelled_data.iloc[:,:-4]\n",
    "y = labelled_data.iloc[:,-4]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y,random_state=0,train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a16951c",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[20:53:38] C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/multiclass_obj.cu:120: SoftmaxMultiClassObj: label must be in [0, num_class).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-90749071798d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mdtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 生成数据集格式\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mnum_rounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# xgboost模型训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# 对测试集进行预测\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m--> 189\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1500\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \"\"\"\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [20:53:38] C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/multiclass_obj.cu:120: SoftmaxMultiClassObj: label must be in [0, num_class)."
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 3,\n",
    "    'gamma': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'lambda': 2,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.75,\n",
    "    'min_child_weight': 3,\n",
    "    'eta': 0.1,\n",
    "    'seed': 1,\n",
    "    'nthread': 4,\n",
    "}\n",
    "\n",
    "plst = list(params.items())\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train) # 生成数据集格式\n",
    "num_rounds = 500\n",
    "model = xgb.train(plst, dtrain, num_rounds) # xgboost模型训练\n",
    "\n",
    "# 对测试集进行预测\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(\"accuarcy: %.2f%%\" % (accuracy*100.0))\n",
    "\n",
    "# 显示重要特征\n",
    "plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f96709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agglomerative.complete.labels \n",
    "#define x,y\n",
    "x1 = labelled_data.iloc[:,:11]\n",
    "y1 = labelled_data.iloc[:,-4]\n",
    "#get train/test data\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, test_size=0.3, random_state=2018)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af234c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "#model training\n",
    "dt_model1 = DecisionTreeClassifier(random_state=2018)\n",
    "dt_model1.fit(x1_train, y1_train)\n",
    "#test the model with test dataset\n",
    "pre_y1 = dt_model1.predict(x1_test)\n",
    "accuracy_s1 = accuracy_score(y1_test, pre_y1)\n",
    "accuracy_s1\n",
    "y1_score = dt_model1.predict_proba(x1_test)\n",
    "y1_score\n",
    "\n",
    "#prediction on non-whitelist data\n",
    "prediction1 = dt_model1.predict(nw_data)\n",
    "prediction1\n",
    "prob1 = dt_model1.predict_proba(nw_data)\n",
    "prob1[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58bb72af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 2 0 1 0 0 0 2 1 0 0 0 0 0 0 0 0 0]\n",
      "[[0.88 0.04 0.07 0.   0.01]\n",
      " [0.87 0.07 0.05 0.   0.01]\n",
      " [0.88 0.09 0.02 0.   0.01]\n",
      " [0.19 0.23 0.42 0.11 0.05]\n",
      " [0.89 0.08 0.02 0.   0.01]\n",
      " [0.27 0.69 0.01 0.   0.03]\n",
      " [0.78 0.15 0.05 0.   0.02]\n",
      " [0.78 0.04 0.12 0.02 0.04]\n",
      " [0.82 0.13 0.05 0.   0.  ]\n",
      " [0.28 0.01 0.66 0.04 0.01]\n",
      " [0.18 0.76 0.02 0.   0.04]\n",
      " [0.88 0.1  0.01 0.   0.01]\n",
      " [0.9  0.07 0.02 0.   0.01]\n",
      " [0.91 0.06 0.03 0.   0.  ]\n",
      " [0.85 0.08 0.06 0.   0.01]\n",
      " [0.89 0.08 0.02 0.   0.01]\n",
      " [0.74 0.21 0.02 0.01 0.02]\n",
      " [0.89 0.01 0.06 0.04 0.  ]\n",
      " [0.89 0.07 0.03 0.   0.01]\n",
      " [0.88 0.08 0.04 0.   0.  ]]\n",
      "unmatched num:  9266\n"
     ]
    }
   ],
   "source": [
    "#random forest(currently good)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create the model with 100 trees\n",
    "rf_model1 = RandomForestClassifier(n_estimators=100, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "# Fit on training data\n",
    "rf_model1.fit(x1_train, y1_train)\n",
    "\n",
    "# Actual class predictions\n",
    "rf_predictions1 = rf_model1.predict(x1_test)\n",
    "\n",
    "# Probabilities for each class\n",
    "rf_probs1 =rf_model1.predict_proba(x1_test)[:, 1]\n",
    "# rf_probs\n",
    "rf_predictions\n",
    "\n",
    "#prediction on non_whitelist data\n",
    "predictions1 = rf_model1.predict(nw_data)\n",
    "print(predictions1[20:40])\n",
    "proba1 = rf_model1.predict_proba(nw_data)\n",
    "print(proba1[20:40])\n",
    "proba1 = list(proba1)\n",
    "count1 = 0\n",
    "for i in proba1:\n",
    "    if max(i)<0.7:\n",
    "        count1 += 1\n",
    "print(\"unmatched num: \",count1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7e96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = labelled_data.iloc[:,:11]\n",
    "y1 = labelled_data.iloc[:,-4]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,random_state=0,train_size=0.7)\n",
    "ss_x = StandardScaler()\n",
    "ss_y = StandardScaler()\n",
    "x_train = ss_x.fit_transform(x_train)\n",
    "x_test = ss_x.transform(x_test)\n",
    "\n",
    "#model training\n",
    "model_GBDT = GradientBoostingClassifier(random_state=10)\n",
    "model_GBDT.fit(x_train,y_train)\n",
    "y_pred = model_GBDT.predict(x_train)\n",
    "y_predprob = model_GBDT.predict_proba(x_train)[:,1]\n",
    "\n",
    "#predict on non whitelist data\n",
    "model_GBDT.predict(nw_data.head(20))\n",
    "prob_GBDT = model_GBDT.predict_proba(nw_data)\n",
    "prob_GBDT\n",
    "count_GBDT = 0\n",
    "for i in range(len(prob_GBDT)):\n",
    "    if np.max(prob_GBDT[i])>0.9:\n",
    "        count_GBDT += 1\n",
    "print(count_GBDT)\n",
    "#     print(np.max(prob_GBDT[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
